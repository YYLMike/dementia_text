{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "from gensim.corpora import WikiCorpus\n",
    "from gensim.models import word2vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "import multiprocessing\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentate the wiki corpus and save it\n",
    "\n",
    "import jieba\n",
    "jieba.set_dictionary('../data/dict.txt.big')\n",
    "def corpus_to_seglist(corpus):\n",
    "    file2 = open('seg_result.txt', 'w')\n",
    "    with open(corpus) as f:\n",
    "        for line in f:\n",
    "#             line = line.encode(sys.stdin.encoding, \"replace\").decode(sys.stdin.encoding)\n",
    "            line = re.sub(\"[^\\u4e00-\\u9fff]\",\"\", line)\n",
    "#             print(line)\n",
    "            if len(line) > 2:\n",
    "                seg_line = jieba.lcut(line)\n",
    "                for token in seg_line:\n",
    "                    file2.write(token + ' ')\n",
    "                file2.write('\\n')\n",
    "        file2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /home/yyliu/code/NLP/data/dict.txt.big ...\n",
      "Loading model from cache /tmp/jieba.u74f96b08eeb68fe4b0ac4c13a6f276ed.cache\n",
      "Loading model cost 1.287 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "# segmentate corpus to word list\n",
    "seg_wiki_zhs_list = corpus_to_seglist('../data/wiki.zht.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-28 00:22:34,152: INFO: collecting all words and their counts\n",
      "2018-03-28 00:22:34,155: INFO: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-03-28 00:22:37,494: INFO: PROGRESS: at sentence #10000, processed 11224644 words, keeping 542476 word types\n",
      "2018-03-28 00:22:39,934: INFO: PROGRESS: at sentence #20000, processed 19178363 words, keeping 789598 word types\n",
      "2018-03-28 00:22:44,999: INFO: PROGRESS: at sentence #30000, processed 26289881 words, keeping 969473 word types\n",
      "2018-03-28 00:22:48,191: INFO: PROGRESS: at sentence #40000, processed 32819749 words, keeping 1136573 word types\n",
      "2018-03-28 00:22:54,683: INFO: PROGRESS: at sentence #50000, processed 38974217 words, keeping 1290087 word types\n",
      "2018-03-28 00:22:57,513: INFO: PROGRESS: at sentence #60000, processed 44753384 words, keeping 1421651 word types\n",
      "2018-03-28 00:23:00,051: INFO: PROGRESS: at sentence #70000, processed 50173268 words, keeping 1543088 word types\n"
     ]
    }
   ],
   "source": [
    "# training word2vec\n",
    "logging.basicConfig(format='%(asctime)s: %(levelname)s: %(message)s', level=logging.INFO)\n",
    "\n",
    "num_features = 700\n",
    "context = 20\n",
    "min_count = 20\n",
    "workers = multiprocessing.cpu_count()\n",
    "model = word2vec.Word2Vec(LineSentence('../../data/seg_wiki.zht.txt'), size=num_features, \n",
    "                window=context, min_count=min_count, workers=workers)\n",
    "model.init_sims(replace=True)\n",
    "model.save('700features_20context_20mincount_zht')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
