{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Building prefix dict from /home/yyliu/code/NLP/data/dict.txt.big ...\n",
      "Loading model from cache /tmp/jieba.u74f96b08eeb68fe4b0ac4c13a6f276ed.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of train set: 873\n",
      "sentence number of dementia subject: 442\n",
      "sentence number of control normal subject: 431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 1.150 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "import data_preprocess\n",
    "CONTROL_TOTAL = 'control_origin.txt'\n",
    "DEMENTIA_TOTAL = 'dementia_origin.txt'\n",
    "x_train, y_train = data_preprocess.read_sentence(DEMENTIA_TOTAL, CONTROL_TOTAL)\n",
    "y_train = data_preprocess.label_to_scalar(y_train)\n",
    "x_train_seg = data_preprocess.segmentation(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "w2v_model = gensim.models.Word2Vec.load('../wordvec_model/500features_20context_20mincount_zht')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(10000)\n",
    "tokenizer.fit_on_texts(w2v_model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tokens = tokenizer.texts_to_sequences(x_train_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9851088201603666\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "num_tokens = [len(tokens) for tokens in x_train_tokens]\n",
    "num_tokens = np.array(num_tokens)\n",
    "pad_len = np.mean(num_tokens) + 3*np.std(num_tokens)\n",
    "pad_len = int(pad_len)\n",
    "print(np.sum(num_tokens<pad_len)/len(num_tokens))\n",
    "print(pad_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "x_train_pad = pad_sequences(x_train_tokens, maxlen=pad_len, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = pad_len\n",
    "EMBEDDING_DIM = 500\n",
    "num_words=10000\n",
    "DROPOUT_LAYER = True\n",
    "LSTM_LAYER = True\n",
    "dropout_rate = 0.5\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nn_model(embedding_matrix, pad_len):\n",
    "    # Architect Model\n",
    "    inputs = Input(shape=(pad_len,))\n",
    "    net = inputs\n",
    "    if True:\n",
    "        net = Embedding(input_dim=len(embedding_matrix),\n",
    "                        output_dim=EMBEDDING_DIM,\n",
    "                        weights=[embedding_matrix],\n",
    "                        input_length=SEQUENCE_LENGTH,\n",
    "                        trainable=False)(net)\n",
    "    else:\n",
    "        net = Embedding(input_dim=num_words,\n",
    "                        output_dim=EMBEDDING_DIM,\n",
    "                        input_length=SEQUENCE_LENGTH)(net)\n",
    "\n",
    "    pathway1 = Conv1D(kernel_size=3, strides=1, filters=64, padding='same',\n",
    "                      activation='relu', name='conv_1')(net)\n",
    "    pathway1 = MaxPool1D(pool_size=SEQUENCE_LENGTH)(pathway1)\n",
    "    pathway2 = Conv1D(kernel_size=4, strides=1, filters=64, padding='same',\n",
    "                      activation='relu', name='conv_2')(net)\n",
    "    pathway2 = MaxPool1D(pool_size=SEQUENCE_LENGTH)(pathway2)\n",
    "    pathway3 = Conv1D(kernel_size=5, strides=1, filters=64, padding='same',\n",
    "                      activation='relu', name='conv_3')(net)\n",
    "    pathway3 = MaxPool1D(pool_size=SEQUENCE_LENGTH)(pathway3)\n",
    "    net = concatenate([pathway1, pathway2, pathway3], axis=2)\n",
    "    if DROPOUT_LAYER:\n",
    "        net = Dropout(rate=dropout_rate)(net)\n",
    "    if LSTM_LAYER:\n",
    "        if DROPOUT_LAYER:\n",
    "            net = LSTM(units=32, return_sequences=True,\n",
    "                       name='LSTM_1', dropout=dropout_rate)(net)\n",
    "            net = LSTM(units=8, name='LSTM_2', dropout=dropout_rate)(net)\n",
    "        else:\n",
    "            net = LSTM(units=32, return_sequences=True, name='LSTM_1')(net)\n",
    "            net = LSTM(units=8, name='LSTM_2')(net)\n",
    "\n",
    "    net = Dense(1, activation='sigmoid')(net)\n",
    "    net = Flatten()(net)\n",
    "    outputs = net\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='Adam', loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_val(x_train_pad, y_train, n_folds, tb):\n",
    "    # K fold cross validation\n",
    "    skf = StratifiedKFold(y_train, n_folds=n_folds, shuffle=True)\n",
    "    best_model = None\n",
    "    last_acc = 0\n",
    "    acc_avg = 0\n",
    "    word_embedding = w2v_model.wv.vectors\n",
    "#     for word, i in word_index.items():\n",
    "#         embedding_vector = word_index.get(word)\n",
    "#         if embedding_vector is not None:\n",
    "#             word_embedding[i] = embedding_vector\n",
    "    for i, (train, val) in enumerate(skf):\n",
    "        print('Running fold: ', str(i+1))\n",
    "        model = get_nn_model(word_embedding, pad_len)\n",
    "        model.fit(x_train_pad[train], y_train[train],\n",
    "                  epochs=EPOCHS, batch_size=BATCH_SIZE, shuffle=True, verbose=2, callbacks=[tb])\n",
    "        result = model.evaluate(x_train_pad[val], y_train[val])\n",
    "\n",
    "        print('Validation acc: {}'.format(result[1]))\n",
    "        acc_avg += result[1]\n",
    "        if result[1] > last_acc:\n",
    "            best_model = model\n",
    "            y_pred = model.predict(x_train_pad[val])\n",
    "#             plot_roc_curve(y_train[val], y_pred, out_dir)\n",
    "        last_acc = result[1]\n",
    "    acc_avg /= n_folds\n",
    "    return best_model, acc_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running fold:  1\n",
      "WARNING:tensorflow:From /home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/backend.py:1456: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/backend.py:1557: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Epoch 1/10\n",
      " - 2s - loss: 0.6912 - acc: 0.5610\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.6880 - acc: 0.5466\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.6695 - acc: 0.6657\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.6373 - acc: 0.6930\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.5701 - acc: 0.7374\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.4960 - acc: 0.7891\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.4627 - acc: 0.7891\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.4392 - acc: 0.8063\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.3747 - acc: 0.8407\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.3395 - acc: 0.8494\n",
      "176/176 [==============================]176/176 [==============================] - 0s 1ms/step\n",
      "\n",
      "Validation acc: 0.75\n",
      "Running fold:  2\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[259425,500] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: embedding_1/embeddings/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@embedding_1/embeddings\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](embedding_1/embeddings, embedding_1/embeddings/Initializer/random_uniform)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'embedding_1/embeddings/Assign', defined at:\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n    handle._run()\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/tornado/ioloop.py\", line 760, in _run_callback\n    ret = callback()\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-f7e767f198d2>\", line 18, in <module>\n    model, acc_avg = k_fold_cross_val(x_train_pad, y_train, 5, tb)\n  File \"<ipython-input-9-d3d44fa8b948>\", line 14, in k_fold_cross_val\n    model = get_nn_model(word_embedding, pad_len)\n  File \"<ipython-input-8-42e26010d35a>\", line 10, in get_nn_model\n    trainable=False)(net)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/topology.py\", line 258, in __call__\n    output = super(Layer, self).__call__(inputs, **kwargs)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 636, in __call__\n    self.build(input_shapes)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/layers/embeddings.py\", line 123, in build\n    dtype=self.dtype)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/topology.py\", line 220, in add_weight\n    trainable=trainable)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 504, in add_variable\n    partitioner=partitioner)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1262, in get_variable\n    constraint=constraint)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1097, in get_variable\n    constraint=constraint)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 435, in get_variable\n    constraint=constraint)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 404, in _true_getter\n    use_resource=use_resource, constraint=constraint)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 806, in _get_single_variable\n    constraint=constraint)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 229, in __init__\n    constraint=constraint)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 366, in _init_from_args\n    validate_shape=validate_shape).op\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 276, in assign\n    validate_shape=validate_shape)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 59, in assign\n    use_locking=use_locking, name=name)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[259425,500] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: embedding_1/embeddings/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@embedding_1/embeddings\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](embedding_1/embeddings, embedding_1/embeddings/Initializer/random_uniform)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[259425,500] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: embedding_1/embeddings/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@embedding_1/embeddings\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](embedding_1/embeddings, embedding_1/embeddings/Initializer/random_uniform)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f7e767f198d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistogram_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_images\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk_fold_cross_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-d3d44fa8b948>\u001b[0m in \u001b[0;36mk_fold_cross_val\u001b[0;34m(x_train_pad, y_train, n_folds, tb)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Running fold: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_nn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         model.fit(x_train_pad[train], y_train[train],\n\u001b[1;32m     16\u001b[0m                   epochs=EPOCHS, batch_size=BATCH_SIZE, shuffle=True, verbose=2, callbacks=[tb])\n",
      "\u001b[0;32m<ipython-input-8-42e26010d35a>\u001b[0m in \u001b[0;36mget_nn_model\u001b[0;34m(embedding_matrix, pad_len)\u001b[0m\n\u001b[1;32m      8\u001b[0m                         \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                         \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSEQUENCE_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                         trainable=False)(net)\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         net = Embedding(input_dim=num_words,\n",
      "\u001b[0;32m~/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;31m# Optionally load weight values that were specified at layer instantiation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_initial_weights'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_weights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/topology.py\u001b[0m in \u001b[0;36mset_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m    425\u001b[0m       \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m     \u001b[0mparam_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mpv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/backend.py\u001b[0m in \u001b[0;36mbatch_get_value\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m   2406\u001b[0m   \"\"\"\n\u001b[1;32m   2407\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2408\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2409\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2410\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    380\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m       \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m    607\u001b[0m       \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m       \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[259425,500] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: embedding_1/embeddings/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@embedding_1/embeddings\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](embedding_1/embeddings, embedding_1/embeddings/Initializer/random_uniform)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'embedding_1/embeddings/Assign', defined at:\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n    handle._run()\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/tornado/ioloop.py\", line 760, in _run_callback\n    ret = callback()\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-f7e767f198d2>\", line 18, in <module>\n    model, acc_avg = k_fold_cross_val(x_train_pad, y_train, 5, tb)\n  File \"<ipython-input-9-d3d44fa8b948>\", line 14, in k_fold_cross_val\n    model = get_nn_model(word_embedding, pad_len)\n  File \"<ipython-input-8-42e26010d35a>\", line 10, in get_nn_model\n    trainable=False)(net)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/topology.py\", line 258, in __call__\n    output = super(Layer, self).__call__(inputs, **kwargs)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 636, in __call__\n    self.build(input_shapes)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/layers/embeddings.py\", line 123, in build\n    dtype=self.dtype)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/topology.py\", line 220, in add_weight\n    trainable=trainable)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 504, in add_variable\n    partitioner=partitioner)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1262, in get_variable\n    constraint=constraint)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1097, in get_variable\n    constraint=constraint)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 435, in get_variable\n    constraint=constraint)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 404, in _true_getter\n    use_resource=use_resource, constraint=constraint)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 806, in _get_single_variable\n    constraint=constraint)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 229, in __init__\n    constraint=constraint)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 366, in _init_from_args\n    validate_shape=validate_shape).op\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 276, in assign\n    validate_shape=validate_shape)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 59, in assign\n    use_locking=use_locking, name=name)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"/home/yyliu/anaconda3/envs/NLP/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[259425,500] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: embedding_1/embeddings/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@embedding_1/embeddings\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](embedding_1/embeddings, embedding_1/embeddings/Initializer/random_uniform)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "# keras module\n",
    "from tensorflow.python.keras.models import Model, load_model\n",
    "from tensorflow.python.keras.layers import Dense, LSTM, Embedding, Input, Conv1D, MaxPool1D, concatenate, Flatten, Dropout\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "#sklearn module\n",
    "from sklearn.metrics import roc_auc_score, auc, roc_curve\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "import datetime\n",
    "import os\n",
    "message = 'CNN_text_embedding'\n",
    "timestamp = datetime.datetime.now().isoformat()\n",
    "out_dir = os.path.abspath(os.path.join(os.path.curdir, \"runs_2\", timestamp+message, \"summaries\"))\n",
    "tb = TensorBoard(log_dir=out_dir, histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "model, acc_avg = k_fold_cross_val(x_train_pad, y_train, 5, tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
