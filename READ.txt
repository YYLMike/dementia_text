file list: jieba_cut.py, mfcc_feature.py, postag.py, filter_punctuation.py, RNN.py, train_word2vec_model.py, wikiXMLtoTXT.py, word2vec.py, word2vec_wiki.py

Section 1: Unlabeled clustering
postag.py: K mean分群先利用jieba_cut.py分詞，在執行postag完成語法、語意的分群

Section 2: Word-embedding and RNN LSTM
jieba_cut.py: 需要用到dict.big.txt來當作分詞的字典
filter_punctuation.py: 將被分詞好的訓練資料做標點符號濾除
train_word2vec_model.py: 利用分詞好的wiki-zh檔案來建立Word2Vec的模型，並輸出model檔
word2vec_wiki.py: 利用建立好的wiki-zh的wordvector模型將文字庫中的每個詞轉換成向量並存成pickle
word2vec.py: 利用之前萌典的wordvector將文字轉成向量並存成pickle

